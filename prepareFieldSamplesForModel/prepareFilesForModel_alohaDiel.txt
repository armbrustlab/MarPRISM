###aloha diel

egthomas@grazer:~$ R

#reads in aloha diel polyA metaT number of transcripts mapped to each contig 
> aloha <- read_csv("/mnt/nfs/projects/ryan/NPacAssemblies_2021/joined/D1PA.contig_dat_all.csv")

#get rid of unnecessary variables
> aloha <- aloha %>% select(-c(dmnd_eval, pfam_score, tax_id, pfam))

#load taxa annotation file that was produced with database including 
#marferret and marmicrodb
> tax <- read.table("/mnt/nfs/projects/armbrust-metat/scope_diel/diel_pa_metat/assemblies/annotations/diamond/marferret_v1.1/NPac.D1PA.MarFERReT_v1.1_MMDB.lca.tab")

#make variable for nucleotide id
> tax <- tax %>% mutate(nt_id = str_replace(V1, "_[0-9]{1,}$", ""))

> str(tax$V2)
 int [1:50461546] 2608131 2864 0 2759 1003176 2864 407301 412154 0 2864 ...

#gets rid of rows that have an NA taxa annotation (some unannotated sequences are
#labeled as taxa id 0)
> tax <- tax %>% filter(!is.na(V2))
> tax <- tax %>% filter(V2 != 0)

> str(tax$V3)
 num [1:30008442] 1.67e-25 5.33e-60 2.28e-83 1.38e-15 3.27e-22 ...

#get best taxa annotation
> tax_best <- tax %>% group_by(nt_id) %>% arrange(V3) %>% slice(1)

> tax_best %>% write_csv("~/alohaDiel/NPac.D1PA.MarFERReT_v1.1_MMDB.lca.tab_bestAnnotation_fall2023.csv")

#add taxa annotations of contigs to the number of reads mapped to contig per sample
> nrow(aloha)
[1] 48907619
> aloha_tax <- aloha %>% left_join(tax_best, by = c("nt_id"))
> nrow(aloha_tax)
[1] 48907619

#ungroup dataframe
> aloha_tax <- aloha_tax %>% ungroup()

#gets rid of contigs without taxa annotations
> aloha_tax_noNA <- aloha_tax %>% filter(!is.na(V2))

> aloha_tax_noNA %>% write_csv("~/alohaDiel/abundancesWithTaxa_fall2023.csv")

> tax_best %>% write_csv("~/alohaDiel/NPac.D1PA.MarFERReT_v1.1_MMDB.lca.tab_bestAnnotation_fall2023.csv")

#gather dataframe with mapped reads per contig per sample, taxa annotations 
#into long form
> aloha_gather <- aloha_tax_noNA %>% gather(S14C1_C_2200:S08C1_C_1400, key = "sample", value = "est_counts")

> str(aloha_gather$est_counts)
 num [1:1307045184] 0 0 1.37 1 0 ...

#gets rid of rows for contigs that have 0 transcripts mapped to them in the sample
> aloha_gather <- aloha_gather %>% filter(est_counts > 0)

#concatenate all of the pfam results for the aloha diel polyA metaT contigs
egthomas@grazer:~$ for f in /mnt/nfs/projects/ryan/diel1/completed_assemblies/6tr/Pfam_34.0/*domtblout.tab; do (cat "${f}"; echo) >> ~/aloha_diel_pfamAnnotations; done

#loads pfam annotations for the aloha diel polyA metaT contigs
> res <- read.table("~/alohaDiel/aloha_diel_pfamAnnotations", fill = TRUE)

> str(res$V8)
 chr [1:29801627] "60.1" "59.9" "59.9" "59.3" "59.1" "58.4" "189," "58.2" ...

> res$V8 <- as.numeric(res$V8)

> res$V7 <- as.numeric(res$V7)

#get only pfam annotations that have evalue less than 10^(-5)
> res <- res %>% filter(V7 < 10^(-5))

> #for contig reading frame, get the pfam with the highest score
> best_pfam_dat <- res %>% group_by(V1) %>% slice(which.max(V8))

#there is more than one pfam for each contig reading frame
> res %>% distinct(V1) %>% nrow()
[1] 19521276
> best_pfam_dat %>% distinct(V1) %>% nrow()
[1] 19366981

#writes best pfam for each contig reading frame to a csv
> best_pfam_dat %>% write_csv("~/aloha_diel_pfamAnnotations_bestPfam.tab")

egthomas@grazer:~$ mv ~/aloha_diel_pfamAnnotations_bestPfam.tab alohaDiel/

> best_pfam_dat <- read_csv("~/alohaDiel/aloha_diel_pfamAnnotations_bestPfam.tab")

#make variable for nucleotide id
> pfam <- best_pfam_dat %>% mutate(nt_id = str_replace(V1, "_[0-9]{1,}$", ""))

#gets amino acid id corresponding to nucleotide id 
> aa_nt_pfam <- read_csv("/mnt/nfs/projects/ryan/NPacAssemblies_2021/joined/D1PA.best_pfam.csv") %>% distinct(aa_id, nt_id, knum)

#gets only the pfam annotation for the longest amino acid sequence for each 
#nucleotide id
> pfam_select <- pfam %>% semi_join(aa_nt_pfam, by = c("V1" = "aa_id"))

#now there is only one pfam annotation for nucleotide id
> pfam_select %>% nrow()
[1] 16111747
> pfam_select %>% distinct(nt_id) %>% nrow()
[1] 16111747

#gets rid of unnecessary variables
> pfam_select <- pfam_select %>% select(V1, V4, V5, nt_id)

#adds best pfam annotation to each nucleotide id in counts dataframe
> nrow(aloha_gather)
[1] 154298831
> aloha_gather_merged <- aloha_gather %>% left_join(pfam_select %>% select(-V1), by = c("nt_id"))
Adding missing grouping variables: `V1`
> nrow(aloha_gather_merged)
[1] 154298831

#make variable for station that reads came from
> aloha_gather_merged <- aloha_gather_merged %>% mutate(station = str_extract(sample, "S[0-9]{1,}C{1,}"))

> aloha_gather_merged %>% write_csv("~/alohaDiel/aloha_diel_allSamples_processed_updatedMarferret_marmicroDb2023_noOutliers_fall2023.csv")

###calculates transcripts per million
> aloha_gather_merged <- aloha_gather_merged %>% mutate(length_kb = length/1000)

> aloha_gather_merged <- aloha_gather_merged %>% mutate(est_counts_div_length_kb = est_counts/length_kb)

> mCounts <- aloha_gather_merged %>% group_by(sample, V2) %>% summarize(mCount = sum(est_counts_div_length_kb)/1e6)
`summarise()` has grouped output by 'sample'. You can override using the `.groups` argument.

> mCounts <- mCounts %>% ungroup()

> nrow(aloha_gather_merged)
[1] 154298831
> aloha_gather_merged <- aloha_gather_merged %>% left_join(mCounts, by = c("sample", "V2"))
> nrow(aloha_gather_merged)
[1] 154298831

> aloha_gather_merged <- aloha_gather_merged %>% mutate(tpm = est_counts_div_length_kb/mCount)

> aloha_gather_merged %>% write_csv("~/alohaDiel/alohaDiel_surface_allSamples_processed_updatedMarferret_marmicroDb2023_noOutliers_tpm_fall2023.csv")

#after calculating transcripts per million, get rid of contigs that don't 
#have a pfam annotation
> aloha_gather_merged <- aloha_gather_merged %>% filter(!is.na(V5))

> aloha_gather_merged %>% write_csv("~/alohaDiel/alohaDiel_surface_allSamples_processed_updatedMarferret_marmicroDb2023_noOutliers_tpm_noNAPfam_fall2023.csv")

#loads taxa names corresponding to taxa ids in marferret
> name <- read_csv("/mnt/nfs/projects/marferret/v1/data/MarFERReT.v1.taxa.csv")

> name <- name %>% select(1:4)

> colnames(aloha_gather_merged)[4] <- "tax_id"

#adds taxa names to counts dataframe
> nrow(aloha_gather_merged)
[1] 68084586
> aloha_gather_merged_name <- aloha_gather_merged %>% left_join(name, by = c("tax_id"))
> nrow(aloha_gather_merged_name)
[1] 68084586

#get rid of contigs without taxa names
> aloha_gather_merged_name_noMissingTaxa <- aloha_gather_merged_name %>% filter(!is.na(tax_name))

#load core transcribed genes (CTGS) identified 
#from 10.1038/s41597-023-02842-4
> core <- read_csv("~/MarFERReT.v1.core_genes.csv")

#get just ctgs grouped at level of eukaryotes
> core <- core %>% filter(lineage == "Eukaryota")

#make a dataframe to count the number of ctgs in each species bin by sample
> pfamSummary <- aloha_gather_merged_name_noMissingTaxa %>% semi_join(core, by = c("V5" = "pfam_id"))

#calculate number of ctgs in each species bin by sample
> pfamSummary <- pfamSummary %>% group_by(sample, tax_id, tax_name) %>% distinct(V5) %>% summarize(numCorePfams = n())
`summarise()` has grouped output by 'sample', 'tax_id'. You can override using the `.groups` argument.

#there are a total of 605 eukaryote ctgs
> core %>% distinct(pfam_id) %>% summarize(n = n())
# A tibble: 1 Ã— 1
      n
  <int>
1   605

#calculate proportion of ctgs in each species bin by sample
> pfamSummary <- pfamSummary %>% ungroup() %>% mutate(propCorePfams = numCorePfams/605)

> pfamSummary %>% write_csv("~/alohaDiel/pfamSummary.csv")

#get species bins/samples that have at least 70% of ctgs detected
> pfamSummary <- pfamSummary %>% filter(propCorePfams >= .7)

#gets just the counts for species bins/samples that have at least 70% of ctgs detected
> aloha_gather_merged_name_noMissingTaxa <- aloha_gather_merged_name_noMissingTaxa %>% semi_join(pfamSummary, by = c("tax_id", "sample"))

#for each taxa, sample, and pfam combination, get the total tpm
> aloha_summary <- aloha_gather_merged_name_noMissingTaxa %>% ungroup() %>% dplyr::group_by(sample, tax_id, tax_name, V5) %>% dplyr::summarize(tpm = sum(tpm))
`summarise()` has grouped output by 'sample', 'tax_id', 'tax_name'. You can override using the `.groups` argument.

#ungroup counts summary data
> aloha_summary <- aloha_summary %>% ungroup()

#name pfam variable
> colnames(aloha_summary)[4] <- "pfam"

#make variable for pfam without the digits after decimal
> aloha_summary <- aloha_summary %>% mutate(shortPfam = str_replace(pfam, "\\..{1,}$", ""))

#rename sample variable
> colnames(aloha_summary)[1] <- "sample_id"

#get rid of unnecessary variables
> aloha_summary_spread <- aloha_summary %>% select(sample_id, tax_name, shortPfam, tpm)

#fill in zeroes for missing pfams
> aloha_summary_spread <- aloha_summary_spread %>% spread(key = shortPfam, value = tpm, fill = 0)

#get feature pfams
> pfam <- read_csv("~/Extracted_Pfams_noOutliers_newContaminationMetric_xg.csv")

> merg <- aloha_summary_spread

#find feature pfams missing
> merg <- merg %>% gather(3:6115, key = "pfam", value = "tpm")

> miss <- pfam %>% anti_join(merg, by = c("pfam"))

#fill in missing feature pfams with 0
> miss <- miss %>% mutate(sample_id = "S06C1_A_600", tax_name = "Azadinium spinosum")

> merg <- merg %>% bind_rows(miss)

> merg <- merg %>% spread(key = pfam, value = tpm, fill = 0)

merg %>% select(sample_id:tax_name) %>% write_csv("~/alohaDiel/alohaDiel_surface_tpm_updatedMarferret_marmicroDb2023_sampleTaxa_noOutliers_fixedTPM_fall2023.csv")
merg %>% select(-c(sample_id:tax_name)) %>% write_csv("~/alohaDiel/alohaDiel_surface_tpm_updatedMarferret_marmicroDb2023_noOutliers_fixedTPM_fall2023.csv")

