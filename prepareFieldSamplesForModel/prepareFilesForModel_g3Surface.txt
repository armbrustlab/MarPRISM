###g3 surface 

#concatenate all of the pfam results for the g3 polyA metaT contigs
egthomas@grazer:/mnt/nfs/projects/ryan/Gradients3/PA/assemblies/raw/Pfam34$ for f in *domtblout.tab; do (cat "${f}"; echo) >> ~/prepareG3/G3_pfamAnnotations; done

R

#loads the concatenated pfam results for the g3 polyA metaT contigs
> res <- read.table("G3_pfamAnnotations")

> str(res$V8)
 num [1:27425617] 57.2 57.1 57 56.7 56.7 56.6 56.4 56.2 54.7 54.4 ...

> str(res$V7)
 num [1:27425617] 2.6e-13 2.8e-13 3.0e-13 3.7e-13 3.8e-13 ...

#gets only pfam annotations for with evalue 10^(-5)
> res <- res %>% filter(V7 < 10^(-5))

> #for contig reading frame, get the pfam with the highest score
> best_pfam_dat <- res %>% group_by(V1) %>% slice(which.max(V8))

#writes best pfam for each contig reading frame to a csv
> best_pfam_dat %>% write_csv("G3_pfamAnnotations_bestPfam.tab")
 
egthomas@guppy:/scratch/elaina/g3$ cp /mnt/nfs/projects/armbrust-metat/gradients3/g3_uw_pa_metat/assemblies/annotations/kallisto/unstranded/G3PA.raw.est_counts_unstranded.csv.gz .

#load number of transcripts mapped to each contig for g3 poly A samples
> g3 <- read_csv("G3PA.raw.est_counts_unstranded.csv")

#get rid of unnecessary variables
> g3 <- g3 %>% select(-1)

#gather counts data into long form
> g3 <- g3 %>% gather(G3PA.UW1:G3PA.UW9, key = "sample", value = "est_counts")

> str(g3)
tibble [2,087,537,400 Ã— 5] (S3: tbl_df/tbl/data.frame)
 $ ...1      : num [1:2087537400] 1 2 3 4 5 6 7 8 9 10 ...
 $ target_id : chr [1:2087537400] "G3PA.UW10_TRINITY_DN1763430_c0_g1_i1" "G3PA.UW10_TRINITY_DN1763488_c0_g1_i1" "G3PA.UW10_TRINITY_DN1763501_c0_g1_i1" "G3PA.UW10_TRINITY_DN1763455_c0_g1_i1" ...
 $ length    : num [1:2087537400] 378 515 390 388 383 360 301 324 302 367 ...
 $ sample    : chr [1:2087537400] "G3PA.UW1" "G3PA.UW1" "G3PA.UW1" "G3PA.UW1" ...
 $ est_counts: num [1:2087537400] 1 0 0 1 4 0 0 2 0 0 ...

#gets rid of contigs without any mapped reads
> g3 <- g3 %>% filter(est_counts > 0)

> g3 %>% write_csv("G3PA.raw.est_counts_unstranded_noZeroes.csv")

> g3 <- read_csv("G3PA.raw.est_counts_unstranded_noZeroes.csv")

#loads taxonomic annotation of g3 polyA contigs, made using marferret and marmicrodb
> tax <- read.table("NPac.G3PA_UW.MarFERReT_v1.1_MMDB.lca.tab")

> str(tax$V2)
 int [1:38103601] 0 0 2966 2864 2698737 0 0 0 0 2864 ...

#gets rid of rows that have an NA taxa annotation (some unannotated sequences are
#labeled as taxa id 0)
> tax_noNA <- tax %>% filter(!is.na(V2))
> tax_noNA <- tax_noNA %>% filter(V2 != 0)

#make variable for nucleotide id
> tax_noNA <- tax_noNA %>% mutate(nt_id = str_replace(V1, "_[0-9]{1,}$", ""))

> str(tax_noNA$V3)
 num [1:22954448] 9.46e-11 3.34e-07 8.81e-71 2.31e-40 3.85e-39 ...

#gets best taxa annotation for nucleotide id
> tax_best <- tax_noNA %>% group_by(nt_id) %>% arrange(V3) %>% slice(1)
 
tax_best %>% write_csv("~/g3/NPac.G3PA_UW.MarFERReT_MarMicroDB.lca.tab_best_fall2023.csv")

> tax_best <- read_csv("~/g3/NPac.G3PA_UW.MarFERReT_MarMicroDB.lca.tab_best_fall2023.csv")

#gets rid of contigs without taxonomic annotations
> tax_best <- tax_best %>% filter(V2 != 0)
> tax_best <- tax_best %>% filter(!is.na(V2))

#gets only mapped data for contigs with taxa annotations
g3 <- g3 %>% semi_join(tax_best, by = c("target_id" = "nt_id"))

#add taxa annotations of contigs to the number of reads mapped to contig per sample
> nrow(g3)
[1] 125540927
> g3_tax <- g3 %>% left_join(tax_best, by = c("target_id" = "nt_id"))
> nrow(g3_tax)
[1] 125540927

> g3_tax %>% write_csv("~/g3/g3AbundancesWithTaxaAnnotations.csv")

#loads best pfam annotation for each contig reading frame
> pfam <- read_csv("~/g3/G3_pfamAnnotations_bestPfam.tab")

#make variable for the nucleotide id 
> pfam <- pfam %>% mutate(nt_id = str_replace(V1, "_[0-9]{1,}$", ""))

#there are more pfam annotations than nucleotide ids
> pfam %>% nrow()
[1] 15396445
> pfam %>% distinct(nt_id) %>% nrow()
[1] 15190523

#for each nucleotide id, get the pfam annotation with the highest score
> pfam <- pfam %>% group_by(nt_id) %>% slice(which.max(V8))

#now there is one pfam annotation for nucleotide id
> pfam %>% nrow()
[1] 15190523

#gets rid of unnecessary variables
> pfam_select <- pfam %>% select(V1, V4, V5, nt_id)

#adds best pfam annotation to each nucleotide id in counts dataframe
> nrow(g3_tax)
[1] 125540927
> g3_gather_merged <- g3_tax %>% left_join(pfam_select %>% select(-V1), by = c("target_id" = "nt_id"))
> nrow(g3_gather_merged)
[1] 125540927

#write data with number of mapped reads per contig per sample, with the contig's 
#pfam and taxa annotation to csv file
> g3_gather_merged %>% write_csv("~/g3/G3_allSamples_processed_updatedMarferret_marmicroDb2023_noOutliers_fall2023.csv")

##calculate transcripts per million
> g3_gather_merged <- g3_gather_merged %>% mutate(length_kb = length/1000)

> g3_gather_merged <- g3_gather_merged %>% mutate(est_counts_div_length_kb = est_counts/length_kb)

> mCounts <- g3_gather_merged %>% group_by(sample, V2) %>% summarize(mCount = sum(est_counts_div_length_kb)/1e6)
`summarise()` has grouped output by 'sample'. You can override using the `.groups` argument.

> mCounts <- mCounts %>% ungroup()

> nrow(g3_gather_merged)
[1] 125540927
> g3_gather_merged <- g3_gather_merged %>% left_join(mCounts, by = c("sample", "V2"))
> nrow(g3_gather_merged)
[1] 125540927
> g3_gather_merged <- g3_gather_merged %>% mutate(tpm = est_counts_div_length_kb/mCount)

> g3_gather_merged %>% write_csv("~/g3/G3_surface_allSamples_processed_updatedMarferret_marmicroDb2023_noOutliers_tpm_fall2023.csv")

#after calculating tpm, get rid of contigs without pfam annotations
> g3_gather_merged <- g3_gather_merged %>% filter(!is.na(V5))

> g3_gather_merged %>% write_csv("~/g3/G3_surface_allSamples_processed_updatedMarferret_marmicroDb2023_noOutliers_tpm_noNAPfam_fall2023.csv")

> g3_gather_merged <- read_csv("~/g3/G3_surface_allSamples_processed_updatedMarferret_marmicroDb2023_noOutliers_tpm_noNAPfam_fall2023.csv")

#make variable for pfam without digits after decimal
> g3_gather_merged <- g3_gather_merged %>% mutate(pfam = str_replace(V5, "\\..{1,}$", ""))

#load taxa name corresponding to each taxa id in marferret
> name <- read_csv("/mnt/nfs/projects/marferret/v1/data/MarFERReT.v1.taxa.csv")

#gets rid of unnecessary variables
> name <- name %>% select(1:4)

#name taxa id
> colnames(g3_gather_merged)[7] <- "tax_id"

#adds taxa names to counts data
> nrow(g3_gather_merged)
[1] 61391368
> g3_gather_merged_name <- g3_gather_merged %>% left_join(name, by = c("tax_id"))
> nrow(g3_gather_merged_name)
[1] 61391368

#gets rid of contigs without taxa names
> g3_gather_merged_name_noMissingTaxa <- g3_gather_merged_name %>% filter(!is.na(tax_name))

#load core transcribed genes (CTGS) identified 
#from 10.1038/s41597-023-02842-4
> core <- read_csv("~/MarFERReT.v1.core_genes.csv")

#get just ctgs grouped at level of eukaryotes
> core <- core %>% filter(lineage == "Eukaryota")

#make a dataframe to count the number of ctgs in each species bin by sample
> pfamSummary <- g3_gather_merged_name_noMissingTaxa %>% semi_join(core, by = c("V5" = "pfam_id"))

#calculate number of ctgs in each species bin by sample
> pfamSummary <- pfamSummary %>% group_by(sample, tax_id, tax_name) %>% distinct(V5) %>% summarize(numCorePfams = n())
`summarise()` has grouped output by 'sample', 'tax_id'. You can override using the `.groups` argument.

#there are a total of 605 eukaryote ctgs
#calculate proportion of ctgs in each species bin by sample
> pfamSummary <- pfamSummary %>% ungroup() %>% mutate(propCorePfams = numCorePfams/605)

> pfamSummary %>% write_csv("~/g3/pfamSummary.csv")

#get species bins/samples that have at least 70% of ctgs detected
> pfamSummary <- pfamSummary %>% filter(propCorePfams >= .7)

#gets just the counts for taxa and sample pairs that have at least 70% ctg detection
> g3_gather_merged_name_noMissingTaxa <- g3_gather_merged_name_noMissingTaxa %>% semi_join(pfamSummary, by = c("tax_id", "sample"))

#for each taxa, sample, and pfam combination, get the total tpm
> g3_summary <- g3_gather_merged_name_noMissingTaxa %>% ungroup() %>% dplyr::group_by(sample, tax_id, tax_name, V5) %>% dplyr::summarize(tpm = sum(tpm))
`summarise()` has grouped output by 'var', 'tax_id', 'tax_name'. You can override using the `.groups` argument.

#ungroup counts summary data
> g3_summary <- g3_summary %>% ungroup()

#name pfam variable
> colnames(g3_summary)[4] <- "pfam"
  
#make pfam variable withotu digits after decimal point
> g3_summary <- g3_summary %>% mutate(shortPfam = str_replace(pfam, "\\..{1,}$", ""))

#rename sample variable
> colnames(g3_summary)[1] <- "sample_id"

#gets rid of unnecessary variables
> g3_summary_spread <- g3_summary %>% select(sample_id, tax_name, shortPfam, tpm)

#gets feature pfams
> pfam <- read_csv("~/Extracted_Pfams_noOutliers_newContaminationMetric_xg.csv")

#gets counts only for feature pfams
> g3_summary_spread <- g3_summary_spread %>% semi_join(pfam, by = c("shortPfam" = "pfam"))

#spread data, filling in missing pfams with 0 tpm
> g3_summary_spread <- g3_summary_spread %>% spread(key = shortPfam, value = tpm, fill = 0)

> merg <- g3_summary_spread

#gather into long form
> merg <- merg %>% gather(3:183, key = "pfam", value = "tpm")

#get missing features
> miss <- pfam %>% anti_join(merg, by = c("pfam"))

#add missing pfams with 0 tpm
> miss <- miss %>% mutate(sample_id = "G3PA.UW1", tax_name = "Bilateria")

> merg <- merg %>% bind_rows(miss)

#spread data into wide form, filling in missing pfams with 0 tpm
> merg <- merg %>% spread(key = pfam, value = tpm, fill = 0)

#gets only taxa names that have spaces because only species bins are wanted
> merg <- merg %>% filter(str_detect(tax_name, " "))

> merg %>% select(sample_id:tax_name) %>% write_csv("~/g3/G3_surface_tpm_updatedMarferret_marmicroDb2023_sampleTaxa_noOutliers_fixedTPM_fall2023.csv")
> merg %>% select(-c(sample_id:tax_name)) %>% write_csv("~/g3/G3_surface_tpm_updatedMarferret_marmicroDb2023_noOutliers_fixedTPM_fall2023.csv")
